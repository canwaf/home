[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "andrew fergusson’s website",
    "section": "",
    "text": "Hi, I’m Andrew - a Linked Data Expert who’s spent the last decade turning messy data problems into elegant solutions across government and finance. I’m that rare breed who gets genuinely excited about metadata, believes good documentation is worth its weight in gold, and isn’t afraid to tell you exactly why your data pipeline needs both. When I’m not evangelizing about linked data or writing Python, you’ll find me at Barry’s Bootcamp, because apparently, I enjoy bashing keyboards, smashing the treadmill, and throwing weights around - much like I enjoy throwing around strong opinions about data engineering best practices.\nThere’s a lot to be said for a personal website without an all-consuming project. Over the last five years, I’ve built some cool things, but let me tell you about csvcubed - a tool born from the trenches of government data engineering that turned a painful linked data publishing process into something actually manageable. It took us from wrestling with presentational spreadsheets to pumping out 5-Star Linked Data at 10x the speed. If you’re into data engineering, linked data, or just enjoy stories about making complex things suck less, this one’s for you.\nNew projects I want to highlight and other bragging rites coming soon?\nFollow me on Mastodon to stay in the loop."
  },
  {
    "objectID": "blog/posts/2024-12-15-csvcubed.html",
    "href": "blog/posts/2024-12-15-csvcubed.html",
    "title": "csvcubed, a personal retrospective",
    "section": "",
    "text": "csvcubed is a tool for building CSV-W files. If you’re wondering what the hell CSV-W is, it’s basically CSV files with extra metadata that provides context and makes them play nice with linked data. It was born out of necessity when I was working on the ONS’s Integrated Data Service’s Dissemination service. Our end product was 5-Star Linked Data, and we needed a way to convert CSV files into RDF. I joined the project during the tail end of 2020 during lockdown as a data engineer and the pipeline for creating CSV-W was a bit of a mess but born of necessity.\nMy onboarding at ONS was great - I was quickly indoctrinated into the power of linked data and the associated standards. My actual job though? Unfucking presentational spreadsheets that locked away most of ONS’s statistical publications. Who wants to unpivot data just to do analysis? Not me, and honestly not the analysts producing them either - nobody wants to do analysis on pivoted data.\nThe tool I initially learned for generating CSV-W was databaker, which Sensible Code knocked together during a hackathon. It did the job of creating tidy data, but that was about it. Our pipeline was ultimately this Airflow-orchestrated mess: scrape a publication’s latest spreadsheet, use databaker to unpivot it, describe the data using something called gss-utils (to which I will not link because CVEs and archived repo related reasons), build a CSV-W, use Swirrl’s csv2rdf tool to convert the CSV-W to RDF, and then publish the RDF to the ONS’s linked data platform (now defunct but it was called IDS Data Explorer). This was a lot of steps, and the pipeline was brittle. Kicking Airflow was a regular occurance.\nI’m a bit of a diva, and sometimes divas are good for getting shit done. The first thing I started to change was the unpivoting process. The databaker tool needed to go - it was slow, unpythonic, and didn’t provide any transferrable skills. Deadend tools are a horrible career investment, so I switched to pandas and dragged the other data engineers with me. This was a good first step, but the reproducibility was still a mess. It was time to build a tool that standardized the production of CSV-W files.\ngssutils was probably my biggest bugbear - while it technically did the job of producing CSV-W files, it was about as transparent as a brick wall. Extending it was a pain in the ass, and adding new predicates to our data was even worse. Since our target was RDF Cube Vocabulary, I conspired with a good work-friend (who went by robons on github) to build a tool that would actually make sense of this CSV-W building process. We originally called it csvwlib but ultimately named it csvcubed.\nHere’s the thing about generating linked observational data - it’s a massive problem space. The RDF Cube Vocabulary is a solid standard, but when you throw in the requirement for harmonization before publication, it’s daunting. RDF Cubes split tabular data into three parts: dimensions (what you slice and dice by), attributes (context for your observations), and the actual observations themselves. In our idealistic world, each dimension needed a code list (basically a SKOS concept scheme), and ideally, you’d just reuse one that already existed in our service. This meant that in the old way of building a cube, you either had to reconcile definitions between datasets to reuse them, or manually write a new concept scheme as a CSV-W. Fun times.\nTo write a RDF Cube-bound CSV-W, you had to write at least one other CSV-W, or worse, reconcile concept definitions across multiple datasets. This was a massive headache for my fellow data engineers - we weren’t statistical subject matter experts, we were data engineers who just wanted to build pipelines that actually worked and could scale. That’s where csvcubed came in.\nThe idea behind csvcubed was simple: you give it a tidy data CSV, and it figures out the rest. Using keywords in the column headers, it works out the dimensions, attributes, and observations of the cube. It automatically creates code lists and concept schemes for dimensions. Suddenly, building a cube wasn’t such a pain in the ass, and the pipeline actually made sense. The tool was a hit - we went from pushing out 1 publication per data engineer per week to smashing out 10 publications per data engineer per week at our peak.\nI’ve moved on since then - these days I’m virtualizing RDF data using ontop in my new gig providing linked data services for DEFRA. But I hope csvcubed keeps being useful for people in the linked data world. I’ve used it a few times in my new role, so I’m still eating my own dog food.\nI’m now not only a diva but fully a linked data partisan. ONS turned me into a true believer, and I’m not looking back. You can claim to do linked data with a black box tool, but let’s be real - if you can’t see how it works, you can’t claim it’s FAIR or 5-Star Linked Data."
  },
  {
    "objectID": "blog/posts/2023-01-29-welcome-to-rougdata.html",
    "href": "blog/posts/2023-01-29-welcome-to-rougdata.html",
    "title": "Welcome to roughdata!",
    "section": "",
    "text": "Turns out, I do need a blog, and it also turns out having backups of my blog posts is a good idea. So here we are.\nThat said, this particular recreation of this blog will be done using the Wayback machine because I actually can’t find my old svbtle hosted blog backups. Glad I was worthy for the archiving, Internet Archive\nI’ll post the old stuff as I determine its suitability for the Internet."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Blog",
    "section": "",
    "text": "csvcubed, a personal retrospective\n\n\n\n\n\n\nprogramming\n\n\ntech\n\n\nportfolio\n\n\n\n\n\n\n\n\n\nDec 15, 2024\n\n\n\n\n\n\n\n\n\n\n\n\nStryd on a Treadmill: Interface Problems\n\n\n\n\n\n\nstryd\n\n\nrunning\n\n\nui\n\n\ncross-post\n\n\n\n\n\n\n\n\n\nFeb 5, 2023\n\n\n\n\n\n\n\n\n\n\n\n\nWelcome to roughdata!\n\n\n\n\n\n\nmeta\n\n\n\n\n\n\n\n\n\nJan 29, 2023\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "blog/posts/stryd-on-treadmill-interface/2023-02-05-stryd-on-a-treadmill.html",
    "href": "blog/posts/stryd-on-treadmill-interface/2023-02-05-stryd-on-a-treadmill.html",
    "title": "Stryd on a Treadmill: Interface Problems",
    "section": "",
    "text": "tl;dr the swipe based interactions on the Phone App for modifying incline on treadmill workouts is not safe and needs to be reimagined, ideally with a calculator button-style instant incline set option.\nBackground: A lot of my running at the moment is within the confines of a HIIT class (Barry’s Bootcamp), mainly to address my resistance training and improve core stability. Approximately half the class is on a treadmill regardless. The Treadmills are a Woodway make, and their user interface looks like the photo below. Speed on the right (miles per hour), incline on the left (percentage incline). There are also ways of modifying each single-press speed change by 0.1 units in two locations on the treads.\n\nJust to describe how to use the interface. You press 5 on the left side (Numbers are 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15), the treadmill blinks into action and begins increasing or decreasing the incline to the desired percentage incline. If you press 10 on the right side, the treadmill begins increasing or decreasing the speed to 10 miles per hour (Buttons are integers 0 to 12). A single button press is all that is required.\nHere’s what it looks like with the swipe interface on using the Stryd app on iOS.\nVideo link to video\nAt timestamp 1:40 my troubles really become apparent where I’m belting out the speed (sub 4 minute kilometres on an incline), but having to fight with the interface. Tapping the down button risks you swiping away the incline options, tapping anywhere risks just jiggling the interface and not registering the tap\nI know Stryd has structured incline runs for Treadmills. It’s a cool feature, and is something I will try out. But I have no idea what my incline asks are going to be because my trainers just shout a speed range and an incline at me. So I can’t use this function to set the incline by way of advancing laps.\nThe reason why I need track my incline this way is something you lovely folk know, Stryd can’t guess your incline on the treadmill and if I assume flat I leave a lot of effort unrecorded. My power curve has changed dramatically since I’ve started recording my inclines.\nWhat I want is a swipe-free interface something like this. I know it’s Frankenstein’s monster but I hope it gets the point across.\n\nAnother option would be 0-9 + an enter button. So you can go to 12% incline by pressing 1, 2, then enter.\nAnywho. That’s me for my very specific feature request in the guise of helping me safely run on a treadmill.\n(Cross posted from Stryd Club Forum, since I needed to host the video somewhere.)"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About Andrew Fergusson",
    "section": "",
    "text": "Andrew Fergusson is a Linked Data Expert and a middling Python engineer. When he’s not banging on about metadata making everyone’s life easier, he’s probably banging the pavement in preparation for the next marathon."
  },
  {
    "objectID": "about.html#education",
    "href": "about.html#education",
    "title": "About Andrew Fergusson",
    "section": "Education",
    "text": "Education\nBSc (Hons) Computing & IT (Computing Science) with Statistics | Open University | October 2015 - September 2021"
  },
  {
    "objectID": "about.html#experience",
    "href": "about.html#experience",
    "title": "About Andrew Fergusson",
    "section": "Experience",
    "text": "Experience\nLinked Data Expert Developer | Telespazio | September 2024 - Present\nLead Data Scientist | Office for National Statistics | May 2022 - September 2024\nSenior Data Engineer | Office for National Statistics | November 2020 - April 2022\nData Engineer | One Manchester | July 2019 - October 2020\nLead Developer (Data Engineering) | BNY Mellon | December 2013 - June 2019"
  }
]